# Polish texts summarization with fine-tuned mT5
The goal of this project is to efficiently fine-tune multilingual transformer T5 to create accurate summaries of Polish texts.

## Methods
Fine-tuned was small version of [mT5](https://huggingface.co/google/mt5-small) which was downloaded from [huggingface](https://huggingface.co/) website. Training was conducted on GPU with cuDNN module. The quality of summaries was assessed based on rouge score.

## Dataset


## Description
The pipeline consisted of 
